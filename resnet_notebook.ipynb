{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f036d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.preprocessing import image\n",
    "#from keras.models import Sequential\n",
    "#from keras.models import Model\n",
    "#from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcfc5571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.1+nv22.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.20.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='23.3.1'),)\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp38-cp38-linux_x86_64.whl (1982.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0mm00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp38-cp38-linux_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.8.0\n",
      "  Downloading torchaudio-0.8.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.8.0+cu111) (1.21.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.9.0+cu111) (9.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='23.3.1'),)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "!pip install tensorflow\n",
    "# Set memory growth configuration for GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be set before initializing GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Initialize TensorFlow after setting the GPU configurations\n",
    "# Your TensorFlow-related code follows here\n",
    "# ...\n",
    "\n",
    "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a266c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing\n",
    "def preprocess(train_data_dir, valid_data_dir, test_data_dir):\n",
    "    img_height, img_width = (224, 224)\n",
    "    batch_size = 32\n",
    "\n",
    "    '''train_data_dir = r\"/content/drive/MyDrive/data/data_dir/cwt_scalograms_dataprocessed/train\"\n",
    "    valid_data_dir = r\"/content/drive/MyDrive/data/data_dir/cwt_scalograms_dataprocessed/val\"\n",
    "    test_data_dir = r\"/content/drive/MyDrive/data/data_dir/cwt_scalograms_dataprocessed/test\"\n",
    "    '''\n",
    "\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       validation_split=0.4)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "    # set as training data\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        valid_data_dir,  # same directory as training data\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "    # set as validation data\n",
    "\n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "    # set as test data\n",
    "\n",
    "    return train_generator, test_generator, valid_generator\n",
    "\n",
    "\n",
    "def model_trainer(epochs = None, **kwargs):\n",
    "    train_data_dir = r\"/workspace/data/data_dir/model-data/train\"\n",
    "    test_data_dir = r\"/workspace/data/data_dir/model-data/test\"\n",
    "    valid_data_dir = r\"/workspace/data/data_dir/model-data/val\"\n",
    "\n",
    "    train_generator, test_generator, valid_generator = preprocess(\n",
    "        train_data_dir=train_data_dir,\n",
    "        test_data_dir=test_data_dir,\n",
    "        valid_data_dir=valid_data_dir)\n",
    "\n",
    "    x, y = test_generator.next()\n",
    "    print(x.shape)\n",
    "    print(f'Number of classification classes : {train_generator.num_classes}')\n",
    "\n",
    "    base_model = ResNet101(include_top=False,weights=\"imagenet\")\n",
    "\n",
    "    #base_model = ResNet101(include_top=False,\n",
    "                          #weights=\"imagenet\")\n",
    "\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    checkpoint_callback = ModelCheckpoint('/workspace/data/data_dir/saved/best/best_model.h5',\n",
    "                                          monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=20,\n",
    "        # steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_generator,  # Replace with your validation dataset\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback]\n",
    "    )\n",
    "\n",
    "    '''\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        for i, (x_batch, y_batch) in enumerate(train_generator):\n",
    "            try:\n",
    "                # Train on the current batch\n",
    "                loss, accuracy = model.train_on_batch(x_batch, y_batch)\n",
    "                print(f\"Batch {i + 1}, Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "            except Exception as e:\n",
    "                # Handle the error (e.g., skip the problematic image)\n",
    "                print(f\"Error in batch {i + 1}: {str(e)}\")\n",
    "\n",
    "                problem_image_bytes = x_batch[0]  # Assuming the problematic image is the first in the batch\n",
    "                problem_image = Image.open(io.BytesIO(problem_image_bytes))\n",
    "                problem_image.save(f'problematic_image_{epoch + 1}_{i + 1}.png')\n",
    "\n",
    "                continue\n",
    "    '''\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    scalogram_model = model_trainer(epochs = 10)\n",
    "    scalogram_model.save('/workspace/data/data_dir/saved/saved_model.h5')\n",
    "\n",
    "\n",
    "    # Save the Keras model as a pickle file\n",
    "    model_filename = '/workspace/data/data_dir/saved/saved_model.pkl'\n",
    "    joblib.dump(scalogram_model, model_filename)\n",
    "\n",
    "    print(f'Model saved as {model_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Function for image preprocessing\n",
    "def preprocess(train_data_dir, valid_data_dir, test_data_dir):\n",
    "    img_height, img_width = (128, 128)  # Adjusted image size\n",
    "    batch_size = 8  # Smaller batch size\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.resnet.preprocess_input,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.4\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    return train_generator, test_generator, valid_generator\n",
    "\n",
    "\n",
    "def model_trainer(epochs=10):\n",
    "    train_data_dir = \"/workspace/data/data_dir/model-data/train\"\n",
    "    test_data_dir = \"/workspace/data/data_dir/model-data/test\"\n",
    "    valid_data_dir = \"/workspace/data/data_dir/model-data/val\"\n",
    "\n",
    "    train_generator, test_generator, valid_generator = preprocess(\n",
    "        train_data_dir=train_data_dir,\n",
    "        test_data_dir=test_data_dir,\n",
    "        valid_data_dir=valid_data_dir\n",
    "    )\n",
    "\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=(128, 128, 3)  # Adjusted input shape based on reduced image size\n",
    "    )\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)  # Adjusted Dense layer\n",
    "    predictions = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        '/workspace/data/data_dir/saved/best/best_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,  # Reduced patience for quicker stopping\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_generator,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scalogram_model = model_trainer(epochs=10)\n",
    "    scalogram_model.save('/workspace/data/data_dir/saved/saved_model.h5')\n",
    "\n",
    "    model_filename = '/workspace/data/data_dir/saved/saved_model.pkl'\n",
    "    tf.keras.models.save_model(scalogram_model, model_filename)  # Save the model without joblib\n",
    "    print(f'Model saved as {model_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebf41b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
