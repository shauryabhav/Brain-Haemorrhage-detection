{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d12cbfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.preprocessing import image\n",
    "#from keras.models import Sequential\n",
    "#from keras.models import Model\n",
    "#from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0acff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1051 images belonging to 3 classes.\n",
      "Found 99 images belonging to 3 classes.\n",
      "Found 200 images belonging to 3 classes.\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 3.4252 - accuracy: 0.7783\n",
      "Epoch 1: val_loss improved from inf to 119.21871, saving model to /workspace/data/data_dir/saved/best/best_model.h5\n",
      "33/33 [==============================] - 14s 412ms/step - loss: 3.4252 - accuracy: 0.7783 - val_loss: 119.2187 - val_accuracy: 0.8788\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 1.1937 - accuracy: 0.8145\n",
      "Epoch 2: val_loss improved from 119.21871 to 16.32347, saving model to /workspace/data/data_dir/saved/best/best_model.h5\n",
      "33/33 [==============================] - 13s 410ms/step - loss: 1.1937 - accuracy: 0.8145 - val_loss: 16.3235 - val_accuracy: 0.8788\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8278\n",
      "Epoch 3: val_loss improved from 16.32347 to 2.03184, saving model to /workspace/data/data_dir/saved/best/best_model.h5\n",
      "33/33 [==============================] - 13s 398ms/step - loss: 0.5528 - accuracy: 0.8278 - val_loss: 2.0318 - val_accuracy: 0.8788\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.4374 - accuracy: 0.8440\n",
      "Epoch 4: val_loss improved from 2.03184 to 0.36670, saving model to /workspace/data/data_dir/saved/best/best_model.h5\n",
      "33/33 [==============================] - 13s 384ms/step - loss: 0.4374 - accuracy: 0.8440 - val_loss: 0.3667 - val_accuracy: 0.8788\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8544\n",
      "Epoch 5: val_loss did not improve from 0.36670\n",
      "33/33 [==============================] - 11s 320ms/step - loss: 0.4072 - accuracy: 0.8544 - val_loss: 0.4868 - val_accuracy: 0.7273\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3709 - accuracy: 0.8535\n",
      "Epoch 6: val_loss did not improve from 0.36670\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.3709 - accuracy: 0.8535 - val_loss: 0.5948 - val_accuracy: 0.6768\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8677\n",
      "Epoch 7: val_loss improved from 0.36670 to 0.34433, saving model to /workspace/data/data_dir/saved/best/best_model.h5\n",
      "33/33 [==============================] - 14s 415ms/step - loss: 0.3506 - accuracy: 0.8677 - val_loss: 0.3443 - val_accuracy: 0.8485\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.8915\n",
      "Epoch 8: val_loss did not improve from 0.34433\n",
      "33/33 [==============================] - 11s 322ms/step - loss: 0.2854 - accuracy: 0.8915 - val_loss: 0.7164 - val_accuracy: 0.6364\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.8773\n",
      "Epoch 9: val_loss did not improve from 0.34433\n",
      "33/33 [==============================] - 11s 325ms/step - loss: 0.2873 - accuracy: 0.8773 - val_loss: 0.6015 - val_accuracy: 0.6566\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.8782\n",
      "Epoch 10: val_loss did not improve from 0.34433\n",
      "33/33 [==============================] - 11s 324ms/step - loss: 0.3209 - accuracy: 0.8782 - val_loss: 0.7488 - val_accuracy: 0.5758\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "def preprocess(train_data_dir, valid_data_dir, test_data_dir):\n",
    "    img_height, img_width = (227, 227)  # AlexNet input size\n",
    "    batch_size = 32\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       validation_split=0.4)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "\n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "\n",
    "    return train_generator, test_generator, valid_generator\n",
    "\n",
    "def alexnet_model(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x = Conv2D(96, (11, 11), strides=(4, 4), activation='relu')(input_layer)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(256, (5, 5), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(384, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(384, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_trainer(epochs=10):\n",
    "    train_data_dir = \"/workspace/data/data_dir/model-data/train\"\n",
    "    test_data_dir = \"/workspace/data/data_dir/model-data/test\"\n",
    "    valid_data_dir = \"/workspace/data/data_dir/model-data/val\"\n",
    "\n",
    "    train_generator, test_generator, valid_generator = preprocess(\n",
    "        train_data_dir=train_data_dir,\n",
    "        test_data_dir=test_data_dir,\n",
    "        valid_data_dir=valid_data_dir)\n",
    "\n",
    "    num_classes = train_generator.num_classes\n",
    "    input_shape = (227, 227, 3)  # Assuming RGB images\n",
    "    model = alexnet_model(input_shape, num_classes)\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint('/workspace/data/data_dir/saved/best/best_model.h5',\n",
    "                                          monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "    \n",
    "    log_dir = \"/workspace/data/data_dir/logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_generator,\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, tensorboard_callback]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    alexnet_model = model_trainer(epochs=10)\n",
    "    alexnet_model.save('/workspace/data/data_dir/saved/saved_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4775572",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4c8f9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 153896), started 0:11:50 ago. (Use '!kill 153896' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b91fd41d4234a0b4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b91fd41d4234a0b4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=/workspace/data/data_dir/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d0ec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  4 07:57:14 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  On   | 00000000:90:00.0 Off |                   On |\n",
      "| N/A   32C    P0    49W / 400W |                  N/A |     N/A      Default |\n",
      "|                               |                      |              Enabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------+\n",
      "| MIG devices:                                                                |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n",
      "|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n",
      "|                  |                      |        ECC|                       |\n",
      "|==================+======================+===========+=======================|\n",
      "|  0   11   0   0  |    618MiB /  4864MiB | 14      0 |  1   0    0    0    0 |\n",
      "|                  |      2MiB /  8191MiB |           |                       |\n",
      "+------------------+----------------------+-----------+-----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c294c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac1ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479ddcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efecdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6562dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
