{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7877289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#from keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "#from keras.applications.resnet50 import ResNet50\n",
    "#from keras.preprocessing import image\n",
    "#from keras.models import Sequential\n",
    "#from keras.models import Model\n",
    "#from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "import joblib\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.resnet import ResNet101\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "555b3d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1750 images belonging to 3 classes.\n",
      "Found 249 images belonging to 3 classes.\n",
      "Found 502 images belonging to 3 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:53:17.996614: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 11:53:18.465252: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-02-29 11:53:18.465426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2839 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB MIG 1g.5gb, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 5.8016 - accuracy: 0.1875\n",
      "Epoch 1: val_loss improved from inf to 1.10727, saving model to /workspace/data/data_dir/saved/best/best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 11:53:19.899305: I tensorflow/stream_executor/cuda/cuda_blas.cc:1804] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 5.8016 - accuracy: 0.1875 - val_loss: 1.1073 - val_accuracy: 0.7812\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4726 - accuracy: 0.9375\n",
      "Epoch 2: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4726 - accuracy: 0.9375 - val_loss: 1.8356 - val_accuracy: 0.8438\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4469 - accuracy: 0.9688\n",
      "Epoch 3: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4469 - accuracy: 0.9688 - val_loss: 2.4299 - val_accuracy: 0.8438\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4530 - accuracy: 0.9688\n",
      "Epoch 4: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4530 - accuracy: 0.9688 - val_loss: 2.8421 - val_accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.9688\n",
      "Epoch 5: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3998 - accuracy: 0.9688 - val_loss: 3.1275 - val_accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.9688\n",
      "Epoch 6: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3207 - accuracy: 0.9688 - val_loss: 3.3229 - val_accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.9688\n",
      "Epoch 7: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2138 - accuracy: 0.9688 - val_loss: 3.4441 - val_accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.9688\n",
      "Epoch 8: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0954 - accuracy: 0.9688 - val_loss: 3.5145 - val_accuracy: 0.8438\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 9: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 3.5662 - val_accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.4882e-04 - accuracy: 1.0000\n",
      "Epoch 10: val_loss did not improve from 1.10727\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 5.4882e-04 - accuracy: 1.0000 - val_loss: 3.6080 - val_accuracy: 0.8438\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def preprocess(train_data_dir, valid_data_dir, test_data_dir):\n",
    "    img_height, img_width = (227, 227)  # Image dimensions assumed for AlexNet\n",
    "    batch_size = 32\n",
    "\n",
    "    # Data generators\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # Preprocess images using PCA\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "    pca.fit(train_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "\n",
    "    # Transform image data using PCA\n",
    "    pca_train_data = pca.transform(train_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "    pca_valid_data = pca.transform(valid_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "    pca_test_data = pca.transform(test_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "\n",
    "    # Create new generators with transformed data\n",
    "    pca_train_generator = (pca_train_data, train_generator[0][1])\n",
    "    pca_valid_generator = (pca_valid_data, valid_generator[0][1])\n",
    "    pca_test_generator = (pca_test_data, test_generator[0][1])\n",
    "\n",
    "    return pca, pca_train_generator, pca_test_generator, pca_valid_generator\n",
    "\n",
    "def pca_model(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Flatten layer\n",
    "    x = Flatten()(input_layer)\n",
    "\n",
    "    # Dense layers\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_trainer(epochs=10):\n",
    "    train_data_dir = \"/workspace/data/data_dir/model-data/train\"\n",
    "    test_data_dir = \"/workspace/data/data_dir/model-data/test\"\n",
    "    valid_data_dir = \"/workspace/data/data_dir/model-data/val\"\n",
    "\n",
    "    pca, pca_train_generator, pca_test_generator, pca_valid_generator = preprocess(\n",
    "        train_data_dir=train_data_dir,\n",
    "        test_data_dir=test_data_dir,\n",
    "        valid_data_dir=valid_data_dir)\n",
    "\n",
    "    num_classes = pca_train_generator[1].shape[1]  # Get number of classes from the generator\n",
    "    input_shape = (pca_train_generator[0].shape[1],)  # Adjust input shape according to PCA components\n",
    "    model = pca_model(input_shape, num_classes)\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint('/workspace/data/data_dir/saved/best/best_model.h5',\n",
    "                                          monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "    \n",
    "    log_dir = \"/workspace/data/data_dir/logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    model.fit(\n",
    "        pca_train_generator[0],\n",
    "        pca_train_generator[1],\n",
    "        epochs=epochs,\n",
    "        validation_data=(pca_valid_generator[0], pca_valid_generator[1]),\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, tensorboard_callback]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pca_model = model_trainer(epochs=10)\n",
    "    pca_model.save('/workspace/data/data_dir/saved/saved_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def preprocess(train_data_dir, valid_data_dir, test_data_dir):\n",
    "    img_height, img_width = (227, 227)  # Image dimensions assumed for AlexNet\n",
    "    batch_size = 32\n",
    "\n",
    "    # Data generators\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        valid_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    test_generator = train_datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=1,\n",
    "        class_mode='categorical')\n",
    "\n",
    "    # Preprocess images using PCA\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "    pca.fit(train_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "\n",
    "    # Transform image data using PCA\n",
    "    pca_train_data = pca.transform(train_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "    pca_valid_data = pca.transform(valid_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "    pca_test_data = pca.transform(test_generator[0][0].reshape(-1, img_height * img_width * 3))\n",
    "\n",
    "    # Create new generators with transformed data\n",
    "    pca_train_generator = (pca_train_data, train_generator[0][1])\n",
    "    pca_valid_generator = (pca_valid_data, valid_generator[0][1])\n",
    "    pca_test_generator = (pca_test_data, test_generator[0][1])\n",
    "\n",
    "    return pca, pca_train_generator, pca_test_generator, pca_valid_generator\n",
    "\n",
    "def pca_model(input_shape, num_classes):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Flatten layer\n",
    "    x = Flatten()(input_layer)\n",
    "\n",
    "    # Dense layers\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "def model_trainer(epochs=10):\n",
    "    train_data_dir = \"/workspace/data/data_dir/model-data/train\"\n",
    "    test_data_dir = \"/workspace/data/data_dir/model-data/test\"\n",
    "    valid_data_dir = \"/workspace/data/data_dir/model-data/val\"\n",
    "\n",
    "    pca, pca_train_generator, pca_test_generator, pca_valid_generator = preprocess(\n",
    "        train_data_dir=train_data_dir,\n",
    "        test_data_dir=test_data_dir,\n",
    "        valid_data_dir=valid_data_dir)\n",
    "\n",
    "    num_classes = pca_train_generator[1].shape[1]  # Get number of classes from the generator\n",
    "    input_shape = (pca_train_generator[0].shape[1],)  # Adjust input shape according to PCA components\n",
    "    model = pca_model(input_shape, num_classes)\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint('/workspace/data/data_dir/saved/best/best_model.h5',\n",
    "                                          monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "    \n",
    "    log_dir = \"/workspace/data/data_dir/logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "    model.fit(\n",
    "        pca_train_generator[0],\n",
    "        pca_train_generator[1],\n",
    "        epochs=epochs,\n",
    "        validation_data=(pca_valid_generator[0], pca_valid_generator[1]),\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, tensorboard_callback]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pca_model = model_trainer(epochs=10)\n",
    "    pca_model.save('/workspace/data/data_dir/saved/saved_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
